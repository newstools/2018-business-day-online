Facebook has responded to criticism that its service may have contributed to sectarian violence in countries such as Sri Lanka and Myanmar, with a new policy that involves removing more types of deliberately inflammatory content from its service. The social networking company has come under fire for refusing in the past to remove such posts entirely, instead downgrading them in its rankings so that they appear in people’s news feeds less often. It has argued that allowing posts to remain while making them less visible “strikes the right balance between free expression and a safe and authentic community”. That has left it defending the right of users to post malicious hoaxes and conspiracy theories. Earlier this week, for instance, it faced criticism for defending its decision not to block Infowars, a website known for spreading conspiracy theories, including claims that the Sandy Hook shooting in the US, in which 20 primary school children were killed in 2010, was staged. On Wednesday, Facebook said it had begun a new policy of blocking “certain forms of misinformation that have contributed to physical harm”. The move is a response to the spread of inflammatory material that does not rise to the level of hate speech of inciting violence directly — both of which are already banned — but which may inflame sectarian or other tensions. “If it’s going to result in real harm, real physical harm, or if you’re attacking individuals, then that content shouldn’t be on the platform,” Mark Zuckerberg, chief executive, said in an interview with online news site Recode. Facebook applied the policy for the first time last month in Sri Lanka, removing material that claimed Muslims were giving or selling poisoned food to Buddhists. The company will rely on local community organisations and intelligence services to flag material they think is being spread to instil violence, in much the same way it already relies on third-party fact checkers to flag fake news. Facebook has been embroiled in a range of controversies in Asia, some of which look set to fall under its new policy. In Myanmar, Facebook has also been accused of allowing its platform, including its Messenger app, to spread hatred between majority Buddhists and minority Muslims. In February, Facebook suspended the account of Wirathu, an extremist Buddhist monk known for inflammatory sermons targeting Muslims. India is among several countries pressuring Facebook to develop more effective measures to counter the spread of fake news on its WhatsApp messaging platform that has led to violent clashes. In recent months, India has seen a spate of at least 18 lynchings triggered by online rumours of the kidnapping of children. The Facebook chief executive’s comments to Recode stirred a small social media storm of their own as he tried to explain why the company did not silence Holocaust deniers. “I find that deeply offensive,” Mr Zuckerberg said. “But at the end of the day, I don’t believe that our platform should take that down because I think there are things that different people get wrong,” he added. “I don’t think that they’re intentionally getting it wrong.” He later clarified his remarks to say he “absolutely didn’t intend to defend the intent of people who deny that”. Facebook has just begun applying its new policy in countries vulnerable to sectarian violence, but it plans to roll it out to all countries in the next few months — potentially drawing in sites such as Infowars, which some critics accuse of deliberately inflaming hatred in ways that could lead to violence. Additional reporting by John Reed in Bangkok and Amy Kazmin in New Delhi